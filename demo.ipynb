{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.estimation import estimate_text_distribution\n",
    "from src.MLE import MLE\n",
    "from src.HC import calculate_hc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Word      logP    log1-P      logQ    log1-Q\n",
      "0          realm -8.456354 -0.000213 -3.296252 -0.037724\n",
      "1      intricate -8.338571 -0.000239 -3.813718 -0.022313\n",
      "2     showcasing -8.589886 -0.000186 -4.158771 -0.015750\n",
      "3        pivotal -8.589886 -0.000186 -4.440337 -0.011862\n",
      "4         stands -8.589886 -0.000186 -4.585943 -0.010246\n",
      "..           ...       ...       ...       ...       ...\n",
      "95     elucidate -8.926358 -0.000133 -6.726793 -0.001199\n",
      "96       crucial -5.417802 -0.004447 -3.256069 -0.039302\n",
      "97  capabilities -5.790864 -0.003060 -3.629708 -0.026882\n",
      "98    foundation -7.203592 -0.000744 -5.035468 -0.006524\n",
      "99    invaluable -8.926358 -0.000133 -6.753821 -0.001167\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "          Word      logP    log1-P      logQ    log1-Q\n",
      "0    intricate -8.735043 -0.000161 -4.094154 -0.016810\n",
      "1       stands -8.735043 -0.000161 -4.797862 -0.008282\n",
      "2   innovative -7.268706 -0.000697 -3.371828 -0.034930\n",
      "3    advancing -8.917364 -0.000134 -5.021972 -0.006613\n",
      "4       paving -8.735043 -0.000161 -4.892980 -0.007527\n",
      "..         ...       ...       ...       ...       ...\n",
      "95       gauge -8.917364 -0.000134 -6.717104 -0.001211\n",
      "96  represents -6.863241 -0.001046 -4.676226 -0.009358\n",
      "97  conclusion -7.159506 -0.000778 -4.979412 -0.006902\n",
      "98    thorough -8.224217 -0.000268 -6.057405 -0.002343\n",
      "99    evolving -7.582363 -0.000509 -5.420217 -0.004436\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "           Word      logP    log1-P      logQ    log1-Q\n",
      "0     intricate -8.596743 -0.000185 -2.554004 -0.080960\n",
      "1   exploration -8.260271 -0.000259 -3.004716 -0.050823\n",
      "2      offering -8.596743 -0.000185 -3.544789 -0.029300\n",
      "3        deeper -8.260271 -0.000259 -3.244411 -0.039772\n",
      "4    intriguing -8.596743 -0.000185 -3.725880 -0.024387\n",
      "..          ...       ...       ...       ...       ...\n",
      "95        plays -6.804984 -0.001109 -4.259095 -0.014236\n",
      "96   influences -8.596743 -0.000185 -6.062240 -0.002332\n",
      "97    versatile -8.596743 -0.000185 -6.062240 -0.002332\n",
      "98        heart -8.596743 -0.000185 -6.077624 -0.002296\n",
      "99         role -5.849473 -0.002886 -3.361852 -0.035286\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "           Word      logP    log1-P      logQ    log1-Q\n",
      "0         realm -8.527511 -0.000198 -3.250668 -0.039519\n",
      "1     intricate -7.988515 -0.000339 -2.758405 -0.065491\n",
      "2   researchers -7.528982 -0.000537 -2.600136 -0.077166\n",
      "3      offering -7.908472 -0.000368 -3.701195 -0.025004\n",
      "4      profound -8.681662 -0.000170 -4.490320 -0.011280\n",
      "..          ...       ...       ...       ...       ...\n",
      "95        heart -8.170836 -0.000283 -5.900425 -0.002742\n",
      "96  reliability -7.072224 -0.000849 -4.811904 -0.008166\n",
      "97       rooted -8.863983 -0.000141 -6.605694 -0.001354\n",
      "98        paves -7.528982 -0.000537 -5.285565 -0.005077\n",
      "99       govern -7.834364 -0.000396 -5.591878 -0.003735\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "            Word      logP    log1-P      logQ    log1-Q\n",
      "0       ensuring -8.363622 -0.000233 -4.203174 -0.015061\n",
      "1       enhances -8.363622 -0.000233 -4.391800 -0.012456\n",
      "2       offering -7.575165 -0.000513 -3.623430 -0.027054\n",
      "3     innovative -7.575165 -0.000513 -3.766769 -0.023398\n",
      "4        notable -8.363622 -0.000233 -4.543350 -0.010695\n",
      "..           ...       ...       ...       ...       ...\n",
      "95      mitigate -7.082688 -0.000840 -5.140007 -0.005875\n",
      "96      advanced -6.714964 -0.001213 -4.779566 -0.008435\n",
      "97     exhibited -7.893619 -0.000373 -5.953299 -0.002601\n",
      "98  introduction -6.882018 -0.001027 -4.951416 -0.007099\n",
      "99   comparative -6.977328 -0.000933 -5.049856 -0.006431\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# for each subject, estimate the distribution of human-written text and AI-generated text\n",
    "for name in [\"CS\",\"EESS\",\"Math\",\"Phys\",\"Stat\"]:\n",
    "    estimate_text_distribution(f\"data/training_data/{name}/human_data.parquet\",f\"data/training_data/{name}/ai_data.parquet\",f\"distribution/{name}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_text_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each subject, estimate the alpha value of mixed text and calculate the error\n",
    "for name in [\"CS\",\"EESS\",\"Math\",\"Phys\",\"Stat\"]:\n",
    "    # load the framework\n",
    "    model=MLE(f\"distribution/{name}.parquet\")\n",
    "    for alpha in [0,0.025,0.05,0.075,0.1,0.125,0.15,0.175,0.2,0.225,0.25]:\n",
    "        estimated,ci=model.inference(f\"data/validation_data/{name}/ground_truth_alpha_{alpha}.parquet\")\n",
    "        error=abs(estimated-alpha)\n",
    "        print(f\"{'Ground Truth':>10},{'Prediction':>10},{'CI':>10},{'Error':>10}\")\n",
    "        print(f\"{alpha:10.3f},{estimated:10.3f},{ci:10.3f},{error:10.3f}\")\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26589\n",
      "Number of words: 26974\n",
      "List of words: ['dql', 'aps', 'mentoring', 'directly', 'quantifiers', 'captured', 'unleashed', 'chat', 'parametrizing', 'ou', 'i_g', 'ase', 'pact', 'linepytorchocr', 'finegrained', 'concealing', 'emotive', 'bayes', 'naturally', 'uct', 'acl20', 'delay', 'interweaved', 'incident', 'nelson', 's3d', 'tips', 'preprocessed', 'younger', 'subcategory', 'revise', 'triple', 'mmn', 'choroid', 'mi2datalab', 'adjacent', 'movielens', 'always', 'defects', 'hgsampling', 'spray', 'resunets', 'ice', 'debugging', 'grounds', 'rgbt', 'unoriginal', 'protruding', 'coveted', 'subterranean', 'powerful', 'fetal', 'liking', 'shutter', 'detection', 'vstreamdrls', 'hoesel', '_x', 'switcher', 'testability', 'burdens', 'multiply', 'anchor', 'dip', 'epilepsiae', 'surges', 'permutation', 'constraint', 'nen', 'adeptness', 'deter', 'royalty', 'porcine', 'meshfree', 'siw', 'biodigitdb', 'heteroscedasticity', 'epidemics', 'sertanejo', 'acknowledges', 'dbb', 'possess', 'wrapping', 'ck', 'systemic', 'write', 'seame', 'generalises', 'evidences', 'traversing', 'road', 'rious', 'lfsr', 'subconscious', 'chemically', 'relighting', 'bustling', 'jupyterhub', 'sdpg', 'executions']\n",
      "=====================================\n",
      "23922\n",
      "Number of words: 24308\n",
      "List of words: ['dql', 'debatrix', 'aps', 'directly', 'unleashed', 'captured', 'mandibles', 'barometric', 'digs', 'precondition', 'parametrizing', 'ou', 'spacechain', 'osseous', 'concealing', 'emotive', 'bayes', 'naturally', 'delay', 'incident', 'tips', 'preprocessed', 'younger', 'revise', 'autocorrelationbased', 'triple', 'tsx', 'choroid', 'magnets', 'lengthened', 'adjacent', 'arborization', '500mhz', 'always', 'defects', 'ice', 'strombolli', 'lebanon', 'debugging', 'gmgan', 'mattress', 'sdri', 'coveted', 'misconducts', 'subterranean', 'powerful', 'fetal', 'liking', 'shutter', 'detection', 'burdens', 'multiply', 'anchor', 'dip', 'hypothesised', 'migrants', 'surges', 'permutation', 'constraint', 'mtutor', 'adeptness', 'deter', 'pco', 'heteroscedasticity', 'fet', 'epidemics', 'acknowledges', 'possess', 'dgpa', 'wrapping', 'ck', 'systemic', 'generalises', 'evidences', 'australian', 'traversing', 'road', 'augmentedmemory', 'lfsr', 'eegnet', 'bustling', 'tpcs', 'executions', 'abundance', 'hypernetwork', 'hinders', 'spectrograms', 'watts', 'multiclass', 'sudden', 'invariants', 'platooning', 'lambda_', 'fibro', 'supseteq', 'local', 'streak', 'sound', 'rosette', 'l2rat']\n",
      "=====================================\n",
      "22219\n",
      "Number of words: 22632\n",
      "List of words: ['dx_t', 'aps', 'mentoring', 'directly', 'tao', 'quantifiers', 'captured', 'brien', 'settle', 'd_m', 'parametrizing', 'phi_', 'wellposeness', 'schmidt', 'transferless', 'feedstocks', 'rouch', 'theoretical', 'sum_i', 'dcflvw', 'concealing', 'isometric', 'quasidiagonality', 'bayes', '2u', 'schr√∂der', 'naturally', 'neill', 'opponents', 'lundberg', 'skeleton', 'catalyzing', 'victorious', 'delay', 'enlarged', 'incident', 'nelson', 'suppers', 'tips', 'misleading', 'dilogarithm', 'ruan', 'subcategory', 'finally', 'voevodsky', 'fitzhugh', 'undesirable', 'triple', 'cacti', 'bandits', 'obeying', 'modern', 'utte', 'calogero', 'mtjpam', 'uniformly', 'r2rils', 'filiform', 'tau_i', 'intuitive', 'adjacent', 'dissect', 'determinantantal', 'irrotational', 'rightarrow0', 'gives', 'aster', 'always', 'choosen', 'nential', 'defects', 'reinvestigate', 'reoccur', 'bodies', 'sala', 'ice', 'pac', 'paraorthomodular', 'knotting', 'sierpi', 'grounds', 'hegselmann', 'clarke', 'arrived', 'minkowski', 'vice', 'booleanizations', 'rdoba', 'limsup_', 'coveted', 'powerful', 'attainable', 'sutured', 'detection', 'assessed', 'curto', 'logician', '2tn', 'orbibundles', '1_h']\n",
      "=====================================\n",
      "28577\n",
      "Number of words: 29002\n",
      "List of words: ['aps', 'directly', 'quantifiers', 'captured', 'uksel', 'parametrizing', 'phi_', 'ou', 'schmidt', 'ase', 'biotissues', 'concealing', 'bayes', 'naturally', 'textemdash', 'timoshenko', 'uct', 'delay', 'femtometer', 'incident', 'nelson', 'sympathetically', 'tips', 'graf', 'younger', 'subcategory', 'revise', 'triple', 'livability', 'popper', 'tracklets', 'calogero', 'magnets', '41p', 'adjacent', 'always', 'defects', 'reinvestigate', 'soundings', 'spray', 'ice', 'transpiring', 'ws2', 'gottesman', 'sierpi', 'grounds', 'cuc', 'coveted', 'powerful', 'fetal', 'detection', 'escuela', 'hollow', '_x', 'testability', 'burdens', 'multiply', 'anchor', 'dip', 'hypothesised', 'iqe', 'migrants', 'surges', 'permutation', 'constraint', 'qahe', 'adeptness', 'spurt', 'deter', 'ephemerides', '7x10', 'centrifugally', 'porcine', 'humming', 'dichalcogenides', 'iskp', 'cgmf', 'fet', 'polytropes', 'pythagorean', 'lesco', 'epidemics', 'acknowledges', 'dbb', '5x10', 'possess', 'wrapping', 'ck', 'systemic', 'volcanoes', 'write', 'generalises', 'evidences', 'australian', 'traversing', 'road', 'hypernuclei', 'chemically', 'functionalizing', 'bustling']\n",
      "=====================================\n",
      "17727\n",
      "Number of words: 17992\n",
      "List of words: ['suicides', 'directly', 'tao', 'vales', 'tesselation', 'equipoise', 'captured', 'brien', 'quantifiers', 'natives', 'pppd', 'bppo', 'precondition', 'settle', 'rgmwm', 'keyboard', 'parametrizing', 'phi_', 'ou', 'readiness', 'schmidt', 'interpolative', 'seriation', 'yao', 'theoretical', 'bo', 'isometric', 'bayes', 'naturally', 'opponents', 'skeleton', 'catalyzing', 'victorious', 'delay', 'enlarged', 'oaxaca', 'incident', 'nelson', 'misleading', 'bacteroidaceae', 'younger', 'finally', 'revise', 'undesirable', 'triple', 'bandits', 'immunizing', 'obeying', 'popper', 'modern', 'seeing', 'uniformly', 'intuitive', 'adjacent', 'alberta', 'dissect', 'gives', 'always', 'defects', 'decelerating', 'reoccur', 'bodies', 'tidy', 'mtmc', 'ice', 'pac', 'quantisations', 'vectorize', 'debugging', 'grounds', 'socioeconomic', 'clarke', 'retest', 'arrived', 'minkowski', 'vice', 'accumbens', 'shielded', 'inappropriate', 'coveted', 'cobhm', 'powerful', 'fetal', 'liking', 'attainable', 'detection', 'assessed', 'bm', 'dementing', 'daylight', 'false', '_x', 'engage', 'certifiably', 'testability', 'burdens', 'multiply', 'moran', 'anchor', 'requires']\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "for name in [\"CS\",\"EESS\",\"Math\",\"Phys\",\"Stat\"]:\n",
    "   human_data=pd.read_parquet(f\"data/training_data/{name}/human_data.parquet\")\n",
    "   ai_data=pd.read_parquet(f\"data/training_data/{name}/ai_data.parquet\")\n",
    "   # Verify that the expected columns are present in each dataset.\n",
    "   if 'human_sentence' not in human_data.columns:\n",
    "       raise ValueError(\"human_sentence column not found in human data\")\n",
    "   if 'ai_sentence' not in ai_data.columns:\n",
    "       raise ValueError(\"ai_sentence column not found in ai data\")\n",
    "   # Calculate HC-discrepancy value\n",
    "   num_words, hc_words = calculate_hc(human_data, ai_data)\n",
    "   print(f\"Number of words: {num_words}\")\n",
    "   print(f\"List of words: {hc_words}\")\n",
    "   print(\"=====================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
